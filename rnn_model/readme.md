# Sequence modeling of traffic using 1-to-1 LSTM architecture

The module trains a simple 1 layer LSTM model from a sequence of traffic. The input data is padded to the maximum sequence length found in the data and normalized based on the user-specified method, which will be described below. A zero-vector is then appended to the start of every sequence, such that we can predict the first _real_ element in the sequence. The model output is generated by applying a one timestep lag (e.g. __input__: X<sub>t</sub> -> __output__ X<sub>t+1</sub>), where the aim is to predict the next element in the sequence given the current element. A train-test-split is applied (default: 30%) and the training dataset is used for model training, while the test dataset is used for evaluation. The loss function used is Mean Squared Error, while the evaluation metric used is Cosine Similarity. Lastly, a series of visualization is plotted.

## Getting Started

With a Python 3 environment, install the dependencies from `requirements.txt`

```
pip install -r requirements.txt
```

Execute the following possible commands:

_Basic_
```
python main.py -f 'features.csv'
```
_Complete_
```
python main.py -f 'features.csv' -n 1 -e 100 -s 'results/expt999'
```

Required arguments:
* -f: Directory of feature file to be used for model training

Optional arguments:
* -n : Normalization options for features (default=1)
* -e : Number of epoch for training (default=100)
* -s : Directory for saving visualization plots. If not specified, the plots will be displayed 

Normalization options:
1. Normalize each sample independently into unit vectors
2. Standardize each feature across ALL traffic. [Source](http://cs231n.github.io/neural-networks-2/)
3. Scale each feature between min and max of feature

## Visualization plots

__Plotting the prediction on sequence length at every epoch.__ Motivation: to determine if the model is learning and is able to model after the traffic data

At epoch 1

![plot1](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/train_predict_pktlen2%20(nicer%20diagram)/epoch1.png)

At epoch 10

![plot2](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/train_predict_pktlen2%20(nicer%20diagram)/epoch10.png)

At epoch 20

![plot3](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/train_predict_pktlen2%20(nicer%20diagram)/epoch20.png)

__Plotting the cosine similarity for True packets__

![plot4](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/acc_dist_truepkts_.png)

__Plotting the mean and median cosine similarity over epoch and final cosine similarity for #1 packet__

![plot5](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/expt1/acc_dist_1pkts.png)

__Plotting the mean and median cosine similarity over epoch and final cosine similarity for first \_\_ packets__

First 10 packets
![plot6](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/expt1/acc_dist_10pkts.png)

First 30 packets
![plot7](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/expt1/acc_dist_30pkts.png)

First 60 packets
![plot8](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/expt1/acc_dist_60pkts.png)

First 90 packets
![plot9](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/expt1/acc_dist_90pkts.png)

__Plotting the training and validation loss__

![plot10](https://github.com/llmhyy/tls_atack/blob/master/rnn_model/results/expt1/loss.png)